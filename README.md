# ðŸ§  Manual-RNN-Pytorch

A character-level RNN trained **from scratch** in PyTorch â€” with **manual forward pass**, **backpropagation through time (BPTT)**, **gradient clipping**, and **custom training loop**. No autograd. No fancy APIs. Just raw neurons and tensors.

## âœ¨ Highlights

- âœ… Manual forward pass
- âœ… Hand-coded backward pass (BPTT)
- âœ… Gradient clipping for stability
- âœ… Character-level text generation
- âœ… Training/validation loss tracking
- âœ… Sampling with temperature control
- âœ… 100% `torch.tensor` logic (no `nn.Module`!)

## ðŸ“‰ Loss Curve

![Training Loss](https://github.com/isakovsh/manual-rnn-pytorch/raw/master/loss.png) 

## ðŸ§  Example Training Output ( Actually, my RNN isnâ€™t learning anythingâ€”he's too busy scrolling Instagram ðŸ˜‚ðŸ˜‚ )
Epoch   0 | Loss: 4.4631 | Val Loss: 4.4279
Ggp?tLMAdhlK cQvzcFxp,wx'foqs; alrjGmL3
uIXIHCpp&Lbk
...

Epoch 100 | Loss: 3.9322 | Val Loss: 3.9296
dADwn Ahw;kNghUzpjVAHUKL3eLcNlxnRwkHYeQdt&yoNl  qPeQety,...
...

Epoch 200 | Loss: 3.4338 | Val Loss: 3.4369
YlegAnhdn t:i 
oXi dX ARIfV.We
hT
uW;ns&dcqneeKo ,ctEnhe,...
...

Epoch 300 | Loss: 3.3396 | Val Loss: 3.3493
OQui.sie ! vlww e bagnoh nrfrelc is.Eet;t Ai- eye...
...

Epoch 900 | Loss: 3.3524 | Val Loss: 3.2838
BI JmW,s teWnu
eom
ntoymsd e
ape tawse foahsgarpeltK...
...

